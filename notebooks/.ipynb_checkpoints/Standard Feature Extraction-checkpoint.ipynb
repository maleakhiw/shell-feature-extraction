{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction (Standard Features)\n",
    "\n",
    "**Author**: Maleakhi Agung Wijaya  \n",
    "**Email**: maw219@cam.ac.uk  \n",
    "**Description**: This file contains code for extracting standard features, using conchology domain knowledge. We evaluate the performance of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models, backend as K, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utilities.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "In this section, we will load previously extracted features, following feature extraction steps described in Zhang et al. (https://www.nature.com/articles/s41597-019-0230-3.pdf). The goal of the project is to build a classifier better than their method through exploring different feature extraction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (contains data that we constructed after feature extraction)\n",
    "X_color, y_color = load_domain_knowledge_data(color_domain_knowledge)\n",
    "X_shape, y_shape = load_domain_knowledge_data(shape_domain_knowledge)\n",
    "X_texture, y_texture = load_domain_knowledge_data(texture_domain_knowledge)\n",
    "X_all, y_all = load_domain_knowledge_data(all_domain_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_color: (1340, 12)\n",
      "X_shape: (1340, 142)\n",
      "X_texture: (1340, 4000)\n",
      "X_all: (1340, 164)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_color: {X_color.shape}\")\n",
    "print(f\"X_shape: {X_shape.shape}\")\n",
    "print(f\"X_texture: {X_texture.shape}\")\n",
    "print(f\"X_all: {X_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "In this section, we further expand the feature sets, introducing whitening and dimensionality reduction using PCA when appropriate. Experimentation are set to fairly compare performance with pipeline discussed in the Zhang et al. paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_color_whitening = scaler.fit_transform(X_color)\n",
    "y_color_whitening = y_color\n",
    "\n",
    "X_shape_whitening = scaler.fit_transform(X_shape)\n",
    "y_shape_whitening = y_shape\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "X_texture_pca = pca.fit_transform(scaler.fit_transform(X_texture))\n",
    "y_texture_pca = y_texture\n",
    "X_texture_pca_whitening = scaler.fit_transform(X_texture_pca)\n",
    "y_texture_pca_whitening = y_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components explaining 99% variance 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of components explaining 99% variance {X_texture_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "In this section, we train classifiers and evaluate the performance of the classifiers using the domain knowledge features in isolation and in combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traditional ML Models**  \n",
    "\n",
    "We consider dummy classifier, SVC, and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter configurations and result storage\n",
    "param_grid_svc = {\n",
    "    # random search varying the parameter\n",
    "    'C': [0.1, 1, 10, 100, 1000],  \n",
    "    'gamma': [\"scale\", \"auto\"], \n",
    "    'kernel': [\"rbf\", \"linear\"]\n",
    "}\n",
    "\n",
    "param_dummy = {\n",
    "    \"strategy\": [\"most_frequent\"] # baseline\n",
    "}\n",
    "\n",
    "param_grid_rf = { \n",
    "    'n_estimators': [10, 100, 200],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "# Used to store results for different feature sets\n",
    "list_dict_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop configuration\n",
    "feature_sets = [\n",
    "    (X_all, y_all),\n",
    "    (X_color, y_color),\n",
    "    (X_shape, y_shape),\n",
    "    (X_texture, y_texture),\n",
    "    (X_color_whitening, y_color_whitening),\n",
    "    (X_shape_whitening, y_shape_whitening),\n",
    "    (X_texture_pca, y_texture_pca),\n",
    "    (X_texture_pca_whitening, y_texture_pca_whitening)\n",
    "]\n",
    "feature_sets_name = [\n",
    "    \"all\",\n",
    "    \"color\",\n",
    "    \"shape\",\n",
    "    \"texture\",\n",
    "    \"color_whiten\",\n",
    "    \"shape_whiten\",\n",
    "    \"texture_pca\",\n",
    "    \"texture_pca_whiten\"\n",
    "]\n",
    "\n",
    "## Classifier and hyperparameter loops\n",
    "param_grids = [param_dummy, param_grid_svc, param_grid_rf]\n",
    "classifiers_name = [\"dummy\", \"svc\", \"rf\"]\n",
    "classifiers = [DummyClassifier(), SVC(), RandomForestClassifier()]\n",
    "cmaps = [None, \"plasma\", \"viridis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "all\n",
      "------------------------------\n",
      "dummy\n",
      "Accuracy: 0.007462686567164178\n",
      "F1: 0.00011055831951354338\n",
      "\n",
      "------------------------------\n",
      "svc\n"
     ]
    }
   ],
   "source": [
    "## Evaluation\n",
    "# Iterate over different feature sets\n",
    "for feature_set , feature_set_name in zip(feature_sets, feature_sets_name):\n",
    "\n",
    "    print(\"*\"*50)\n",
    "    print(feature_set_name)\n",
    "    \n",
    "    X = feature_set[0]\n",
    "    y = feature_set[1]\n",
    "    param_grid_mlp[\"input_dim\"][0] = X.shape[1]\n",
    "    \n",
    "    dict_results = generate_dict_results()\n",
    "    # Iterate over different classifiers\n",
    "    for classifier, classifier_name, param_grid, cmap in zip(classifiers, \n",
    "                                                             classifiers_name, \n",
    "                                                             param_grids,\n",
    "                                                             cmaps):\n",
    "        print(\"-\"*30)\n",
    "        print(classifier_name)\n",
    "\n",
    "        list_acc, list_cm, list_f1, list_cv_results = nested_cv_sklearn(classifier, param_grid, X, y, 5)\n",
    "        # Add data to dict_results\n",
    "        dict_results[\"accuracy\"].append(list_acc)\n",
    "        dict_results[\"f1\"].append(list_f1)\n",
    "        dict_results[\"cv_results\"].append(list_cv_results)\n",
    "        dict_results[\"cm\"].append(list_cm)\n",
    "\n",
    "        # Display accuracy, f1, confusion matrix\n",
    "        print(f\"Accuracy: {np.mean(list_acc)}\")\n",
    "        print(f\"F1: {np.mean(list_f1)}\")\n",
    "        cm = sum(list_cm)\n",
    "\n",
    "        if classifier_name != \"dummy\":\n",
    "            plot_confusion_matrix(cm, cmap=cmap)\n",
    "\n",
    "        print()\n",
    "    \n",
    "    list_dict_results.append(dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Networks**  \n",
    "\n",
    "We consider neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
